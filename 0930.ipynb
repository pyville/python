{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python을 이용한 데이터 분석의 실제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 얻기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기초 데이터(Raw Data)를 얻는 것은 가장 기본이 되는 작업이다.\n",
    "\n",
    "대한민국에서 제공하고 있는 공공 데이터는 각각 다음과 같은 방법으로 얻을 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기상 데이터\n",
    "\n",
    "기상자료공개포털(https://data.kma.go.kr) 접속\n",
    "\n",
    "기후통계분석 → 기후분석 → 조건별통계 (탭)\n",
    "\n",
    "조건 설정을 통해 일/월/년/계절별 데이터 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인구 데이터\n",
    "\n",
    "행정안전부(www.mois.go.kr) 접속\n",
    "\n",
    "정책자료 → 통계 → 주민등록 인구통계 → 연령별 인구현황 (탭)\n",
    "\n",
    "연령 구분 단위, 만 연령구분 등 조건 설정을 통해 인구 데이터 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 대중교통 데이터\n",
    "\n",
    "티머니 홈페이지(https://www.t-money.co.kr) 접속\n",
    "\n",
    "좌측 '이용안내' → 대중교통 통계자료 → 엑셀 첨부 파일 내려받기\n",
    "\n",
    "‘버스정류장별 이용현황’, ‘지하철 노선별 역별 이용현황’, ‘지하철 유무임별 이용현황’, ‘지하철 시간대별 이용현황’"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 경로에 파일 저장 완료\n"
     ]
    }
   ],
   "source": [
    "raw_text = '''대한민국 최악의 미제사건이었던 화성 연쇄살인 사건의 범인이 경찰의 최신 DNA 판독기술에 의해 특정되었다. 하지만 범인으로 지목된 이춘재가 자신의 혐의를 완강히 부인하고 있는 상황에서 공소시효가 지난 지금, 사건의 진실을 어떻게 규명할 수 있을까?\n",
    "'그것이 알고 싶다'에서는 사건이 절정으로 치달았던 지난 1992년 4월 28일, '6년간의 살인-화성연쇄살인사건'편에서 사건 당시, 현장 상황과 관계자들의 생생한 증언을 토대로 범인의 정체를 추적한 바 있다. 그리고 약 20여 년 후인 지난 2011년 5월 7일 '800회 특집, 사라진 악마를 찾아서' 편에서는 사건 당시의 기록을, 21세기 첨단 과학수사의 눈으로 살펴보며, 정교한 프로파일링으로 범인의 윤곽을 그려내기도 했다.\n",
    "이날 방송할 1부에서는 과거 방송을 통해 축적된 '그알'만의 단독 자료와 데이터를 활용해서 경찰이 특정한 범인 이춘재와 당시 '그알'이 예측했던 범인의 모습이 얼마나 일치하는지를 살펴본다. 그리고, 범인 특정의 계기가 되었던 첨단 DNA 기법은 무엇인지, 현재까지 범행을 부인하고 있는 이춘재의 혐의가 입증될 수 있을지 살펴본다.\n",
    "이어 오는 10월 5일 방송할 2부에서는 이춘재가 경찰에 체포된 사건이었던 ‘처제 성폭행 살인사건’을 중심으로 범인 이춘재는 어떤 인물인지를 집중 분석한다. 만일 그가 화성 연쇄 사건의 진범이라면, 어떻게 그동안 수사망을 피할 수 있었고, 어떻게 꼬리가 밟히게 된 것인지에 대해 추적한다. 또 처제 살인 직후에도 처가에 들러 일손을 돕는 대담한 행동을 했는가 하면, 1심 재판에서 사형을 선고받고 난 직후 수사관계자에게 ‘고맙다’고 말했다는 이춘재의 심리 상태와 체포와 조사과정, 그리고 수감 기간 동안 보여준 그의 기이한 발언과 행적까지 들여다본다.'''\n",
    "line_list = raw_text.split('\\n') # 줄바꿈 단위로 분리해서 리스트 생성\n",
    "\n",
    "with open('raw_data.txt', 'w') as f: # 한 줄씩 써야 함\n",
    "    for line in line_list:\n",
    "        f.write('{}\\n'.format(line))\n",
    "print('현재 경로에 파일 저장 완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대한민국 최악의 미제사건이었던 화성 연쇄살인 사건의 범인이 경찰의 최신 DNA 판독기술에 의해 특정되었다. 하지만 범인으로 지목된 이춘재가 자신의 혐의를 완강히 부인하고 있는 상황에서 공소시효가 지난 지금, 사건의 진실을 어떻게 규명할 수 있을까?\n",
      "'그것이 알고 싶다'에서는 사건이 절정으로 치달았던 지난 1992년 4월 28일, '6년간의 살인-화성연쇄살인사건'편에서 사건 당시, 현장 상황과 관계자들의 생생한 증언을 토대로 범인의 정체를 추적한 바 있다. 그리고 약 20여 년 후인 지난 2011년 5월 7일 '800회 특집, 사라진 악마를 찾아서' 편에서는 사건 당시의 기록을, 21세기 첨단 과학수사의 눈으로 살펴보며, 정교한 프로파일링으로 범인의 윤곽을 그려내기도 했다.\n",
      "이날 방송할 1부에서는 과거 방송을 통해 축적된 '그알'만의 단독 자료와 데이터를 활용해서 경찰이 특정한 범인 이춘재와 당시 '그알'이 예측했던 범인의 모습이 얼마나 일치하는지를 살펴본다. 그리고, 범인 특정의 계기가 되었던 첨단 DNA 기법은 무엇인지, 현재까지 범행을 부인하고 있는 이춘재의 혐의가 입증될 수 있을지 살펴본다.\n",
      "이어 오는 10월 5일 방송할 2부에서는 이춘재가 경찰에 체포된 사건이었던 ‘처제 성폭행 살인사건’을 중심으로 범인 이춘재는 어떤 인물인지를 집중 분석한다. 만일 그가 화성 연쇄 사건의 진범이라면, 어떻게 그동안 수사망을 피할 수 있었고, 어떻게 꼬리가 밟히게 된 것인지에 대해 추적한다. 또 처제 살인 직후에도 처가에 들러 일손을 돕는 대담한 행동을 했는가 하면, 1심 재판에서 사형을 선고받고 난 직후 수사관계자에게 ‘고맙다’고 말했다는 이춘재의 심리 상태와 체포와 조사과정, 그리고 수감 기간 동안 보여준 그의 기이한 발언과 행적까지 들여다본다.\n"
     ]
    }
   ],
   "source": [
    "with open('raw_data.txt', 'r') as f: # 한 줄씩 써야 함\n",
    "    for line in f.readlines():\n",
    "        print(line, end =\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### csv\n",
    "\n",
    "skip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BeautifulSoup\n",
    "\n",
    "웹 사이트의 텍스트만 가져오거나, HTML을 계층 구조화하여 가져올 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 검색어1홍정욱2홍정욱 딸3시몬스 킹 매트리스 할인4sprx 다이어트5닥터피엘 샤워기67년의 밤7시몬스 킹 매트리스8힐링패치 반띵9메리츠 암보험10박스터11기업은행 채용12라퍼지스토어 아우터특가13백석대학교14닥터피엘15시몬스16허삼영17최성해18남궁원19포르쉐 박스터20태풍경로\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "\n",
    "# 웹 문서에서 soup을 생성한다.\n",
    "# urlopen()이 \"http://\"를 자동으로 추가하지 않는다는 것을 기억하자!\n",
    "soup1 = BeautifulSoup(urlopen(\"http://www.naver.com/\"))\n",
    "\n",
    "print(soup1.get_text().split('급상승 검색어')[1].replace('\\n',''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pandas\n",
    "\n",
    "pandas를 이용하여 웹 사이트의 표 데이터를 불러올 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Games</th>\n",
       "      <th>Gold</th>\n",
       "      <th>Silver</th>\n",
       "      <th>Bronze</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Totals</td>\n",
       "      <td>28</td>\n",
       "      <td>5115.0</td>\n",
       "      <td>5081.0</td>\n",
       "      <td>5486.0</td>\n",
       "      <td>15682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>United States (USA)</td>\n",
       "      <td>27</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>795.0</td>\n",
       "      <td>705.0</td>\n",
       "      <td>2522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Soviet Union (URS)</td>\n",
       "      <td>9</td>\n",
       "      <td>395.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>1010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Great Britain (GBR)</td>\n",
       "      <td>28</td>\n",
       "      <td>263.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>China (CHN)</td>\n",
       "      <td>10</td>\n",
       "      <td>224.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Team Games    Gold  Silver  Bronze  Total\n",
       "153                Totals    28  5115.0  5081.0  5486.0  15682\n",
       "139  United States (USA)     27  1022.0   795.0   705.0   2522\n",
       "110   Soviet Union (URS)      9   395.0   319.0   296.0   1010\n",
       "51   Great Britain (GBR)     28   263.0   295.0   293.0    851\n",
       "24           China (CHN)     10   224.0   167.0   155.0    546"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_html('https://en.wikipedia.org/wiki/All-time_Olympic_Games_medal_table', header=0)\n",
    "summer = df[1].iloc[:,:6]\n",
    "summer.columns = ['Team', 'Games', 'Gold', 'Silver', 'Bronze', 'Total']\n",
    "summer['Team'] = summer['Team'].str.split('[', n=1, expand=True)\n",
    "summer = summer.sort_values('Gold', ascending=False)\n",
    "summer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Games</th>\n",
       "      <th>Gold</th>\n",
       "      <th>Silver</th>\n",
       "      <th>Bronze</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>China (CHN)</td>\n",
       "      <td>10</td>\n",
       "      <td>224.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Japan (JPN)</td>\n",
       "      <td>22</td>\n",
       "      <td>142.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>South Korea (KOR)</td>\n",
       "      <td>17</td>\n",
       "      <td>90.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>North Korea (PRK)</td>\n",
       "      <td>10</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Chinese Taipei (TPE)</td>\n",
       "      <td>14</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Hong Kong (HKG)</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Team Games   Gold  Silver  Bronze Total\n",
       "24            China (CHN)     10  224.0   167.0   155.0   546\n",
       "68             Japan (JPN)    22  142.0   136.0   161.0   439\n",
       "74       South Korea (KOR)    17   90.0    87.0    90.0   267\n",
       "73       North Korea (PRK)    10   16.0    16.0    22.0    54\n",
       "127  Chinese Taipei (TPE)     14    5.0     7.0    12.0    24\n",
       "57        Hong Kong (HKG)     16    1.0     1.0     1.0     3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summer[summer['Team'].str.contains('Korea') | \\\n",
    "       summer['Team'].str.contains('China') | \\\n",
    "       summer['Team'].str.contains('Hong Kong') | \\\n",
    "       summer['Team'].str.contains('Taipei') | \\\n",
    "       summer['Team'].str.contains('Japan') ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pandas, NumPy, matplotlib"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
